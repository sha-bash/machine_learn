import numpy as np
import matplotlib.pyplot as plt

# логарифмическая функция потерь
def log_loss(w, x, y):
    M = np.dot(w, x) * y
    return np.log(1 + np.exp(-M))

# производная логарифмической функции потерь по вектору w
def dlog_loss(w, x, y):
    M = np.dot(w, x) * y
    return -x * y / (1 + np.exp(M))

# обучающая выборка с тремя признаками (третий - константа +1)
x_train = np.array([[5.8, 2.7], [6.7, 3.1], [5.7, 2.9], [5.5, 2.4], [4.8, 3.4], [5.4, 3.4], [4.8, 3.0], [5.5, 2.5], [5.3, 3.7], [7.0, 3.2], [5.6, 2.9], [4.9, 3.1], [4.8, 3.0], [5.0, 2.3], [5.2, 3.4], [5.1, 3.8], [5.0, 3.0], [5.0, 3.3], [4.6, 3.1], [5.5, 2.6], [5.0, 3.5], [6.7, 3.0], [6.0, 2.2], [4.8, 3.1], [6.4, 2.9], [5.6, 3.0], [4.4, 3.0], [4.9, 2.4], [5.6, 3.0], [5.0, 3.6], [5.1, 3.3], [5.8, 4.0], [5.5, 2.4], [5.2, 2.7], [5.1, 3.8], [5.1, 3.5], [5.5, 4.2], [4.9, 3.1], [5.9, 3.2], [5.7, 2.6], [4.7, 3.2], [5.4, 3.9], [5.8, 2.6], [5.1, 3.4], [6.4, 3.2], [5.8, 2.7], [5.6, 2.7], [5.7, 2.8], [5.4, 3.0], [5.0, 3.2], [4.6, 3.4], [6.0, 2.7], [6.6, 3.0], [4.9, 3.0], [4.9, 3.6], [4.4, 3.2], [5.4, 3.4], [6.0, 3.4], [5.9, 3.0], [6.1, 2.8], [5.1, 3.7], [5.5, 3.5], [6.1, 3.0], [6.2, 2.2], [5.7, 3.0], [5.2, 3.5], [5.4, 3.7], [4.6, 3.2], [5.2, 4.1], [5.0, 2.0], [6.8, 2.8], [5.0, 3.5], [6.7, 3.1], [6.3, 3.3], [6.0, 2.9], [4.7, 3.2], [6.6, 2.9], [5.6, 2.5], [4.4, 2.9], [6.2, 2.9], [6.1, 2.9], [4.3, 3.0], [6.9, 3.1], [5.7, 3.8], [5.4, 3.9], [6.1, 2.8], [4.6, 3.6], [5.5, 2.3], [4.8, 3.4], [6.5, 2.8], [6.3, 2.5], [5.1, 3.8], [5.7, 4.4], [5.0, 3.4], [4.5, 2.3], [5.7, 2.8], [5.1, 2.5], [5.1, 3.5], [6.3, 2.3], [5.0, 3.4]])
x_train = np.hstack((x_train, np.ones((x_train.shape[0], 1))))  # добавление столбца с единицами
y_train = np.array([1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1])  # список из целевых меток класса объектов обучающей выборки

n_train = len(x_train)  # размер обучающей выборки
w = np.array([0.0, 1.0, 0.0])  # начальные весовые коэффициенты
nt = 0.0005  # шаг сходимости SGD
lm = 0.01  # скорость "забывания" для Q
N = 1500  # число итераций SGD

Q = np.mean([log_loss(w, x, y) for x, y in zip(x_train, y_train)])  # показатель качества
Q_plot = [Q]

for i in range(N):
    k = np.random.randint(0, n_train - 1)  # случайный индекс
    ek = log_loss(w, x_train[k], y_train[k])  # вычисление потерь для выбранного вектора
    w = w - nt * dlog_loss(w, x_train[k], y_train[k])  # корректировка весов по SGD
    Q = lm * ek + (1 - lm) * Q  # пересчет показателя качества
    Q_plot.append(Q)

print(w)
print(Q_plot)

line_x = list(range(int(np.max(x_train[:, 0]))))  # формирование графика разделяющей линии
line_y = [-x * w[0] / w[1] - w[2] / w[1] for x in line_x]

x_0 = x_train[y_train == 1]  # формирование точек для 1-го
x_1 = x_train[y_train == -1]  # и 2-го классов

plt.scatter(x_0[:, 0], x_0[:, 1], color='red')
plt.scatter(x_1[:, 0], x_1[:, 1], color='blue')
plt.plot(line_x, line_y, color='green')

plt.xlim([0, 45])
plt.ylim([0, 75])
plt.ylabel("длина")
plt.xlabel("ширина")
plt.grid(True)
plt.show()